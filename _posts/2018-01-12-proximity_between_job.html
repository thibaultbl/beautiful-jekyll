---
layout: page
title: Proximity between jobs
subtitle: Document similarity to get job similar to each other + force directed graph in D3 for vizualisation.
use-site-title: true
---

<!DOCTYPE html>
<html>
<head>
<link rel="stylesheet" type="text/css" href="css/code.css">
</head>
<body>
<p> In this post, you can find the code used to find job similar to each other. 
  For this purpose, we used data available on INSEE (French governemental agencies for statistics) website.
  I manage to compute document similarity using description of task related to job.
  </p>
  <p> For the final visualization, I reduced the number of job available but for a complete application, 
    I should probably introduce a new widget to allow user to filter depending on what he want to see. </p>
<figure>
  <figcaption>Library and classes used</figcaption>
  <pre>
    <code>
      # -*- coding: utf-8 -*-
import pandas as pd
from nltk.stem import SnowballStemmer
from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
import networkx as nx
from networkx.readwrite import json_graph
import json
import scipy
import numpy as np

PATH = "U:/D3.Js/Metiers_competences/"
PATH_DATA = PATH + "Data/"
PATH_PLOT = PATH + 'Plot/'

RANDOM_STATE = 42

THRESHOLD = 0.2

stop_words =\
    list(pd.read_csv(PATH_DATA + "stop_word.txt", header=None).iloc[:, 0])
stemmer = SnowballStemmer("french", ignore_stopwords=False)

def create_data_set(url_def, url_job, grand_domaine="INDUSTRIE"):
    definitions =\
        pd.read_csv(url_def,
                    sep=";")
    definitions =\
        definitions.loc[definitions.loc[:, "Grand Domaine"] == grand_domaine, :]
    definitions = definitions.sort_values(by="Libellé")
    definitions =\
        definitions.loc[:, ["Libellé", "code_rome"]].drop_duplicates()
    
     
    jobs =\
        pd.read_csv(url_job,
                    sep=";").rename(columns={"Code ROME":"code_rome"})
    jobs = jobs.loc[:, ["code_rome", "ROME Libellé"]].drop_duplicates()
        
    data = definitions.merge(jobs, how="left", on="code_rome")
    data.columns = ["jobname", "code_rome", "definition"]
    return(data)

class CleanText(BaseEstimator, TransformerMixin):
    """ Apply stemming in text column
    
    Parameters
    ----
    text_col: list of columns to apply stop_word deletion
    stemmer: Stelmer t ouse (from nltk)
    
    Attributes
    ----
    Return pandas dataframe with transformed text column:
        - stop word are deleted
        - stemming is applied
        - every word are converted to lowercase
    
    """
    def __init__(self, text_col=None, stemmer=None, stop_word=None):
        self.stemmer = stemmer
        self.text_col = text_col
        self.stop_word = stop_word
    def __clean_text__(self, x):
        
        return((' '.join(self.stemmer.stem(w.lower()) for w in x.split() 
            if w.lower() not in self.stop_word)))
    def fit(self, df, y=None, **fit_params):
        return self
    def transform(self, df, **transform_params):
        for col in self.text_col:
            df.loc[:, col] = df.loc[:, col].map(self.__clean_text__)
        return df
    
    
class CosineSimilarity(BaseEstimator, ClassifierMixin):  
    """Estimator for cosine similarity Input is tf-idf matrix"""
    def __init__(self, otherParam=None):
        self.otherParam = otherParam
    def fit(self, X, y=None):
        return self
    def predict(self, X, y=None):
        return((X * X.T))
        
class keeped_variable(BaseEstimator, TransformerMixin):
    """Indicate variable to keep in dataset.
    To check that training and test set contain same variables
    """
    def __init__(self, variable_to_keep):
        self.variable_to_keep=variable_to_keep
    def transform(self, X):
        result=X[self.variable_to_keep]
        return result
    def fit(self, X, y=None):
        return self
    
class PandasToSeries(BaseEstimator, TransformerMixin):
    """ Transform a pandas.DataFrame to a numpy.array """
    def __init__(self, col_tokeep):
        self.col_tokeep = col_tokeep
    def fit(self, df, y=None):
        return self
    def transform(self, df, **transform_params):
        return df.loc[:, self.col_tokeep]
    </code>
  </pre>
</figure>
  
  <p> We can see that everything is in a custom transformer to be introduced in a scikit-learn Pipeline.
    I think it's a really good way to have clean code and to reuse snipset of code in many projects. </p>
  <p> Again, it's just a sample of job for demonstration purpose. We kept only job related to health sector 
    and took a small sample (at random) of this job for the visualization.
  
 <figure>
  <figcaption>Main code</figcaption>
  <pre>
    <code>

if __name__== "__main__":
    ############################"
    #    DOCUMENT SIMILARITY
    ############################"
    data = create_data_set(PATH_DATA + "pole-emploi-rome-arborescence-principale.csv",
                           PATH_DATA + "rome-code-rome-definitions.csv",
                           "SANTE")
    # data = data.head(1000)
    data = data.groupby('jobname')['definition'].apply(lambda x: ' '.join(x))\
               .reset_index()
    data = data.head(50)
    # data = data.head(30)
    clean_text = CleanText(["definition"], stemmer, stop_words)
    
    pipe = Pipeline([
            ("clean_text", clean_text),
            ("select_variable", keeped_variable(["definition"])),
            ("to_numpy", PandasToSeries("definition")),
            ("tf_idf", TfidfVectorizer(max_df=0.9, min_df=0.1)),
            ("cosine", CosineSimilarity())
            ])
    pipe.fit(data)
    pca_res = pipe.predict(data)
    
    ############################"
    #    CREATE GRAPH
    ############################"
    cx = scipy.sparse.coo_matrix(pca_res)

    G=nx.Graph()

    for job_number, job in enumerate(data.jobname):
        G.add_node(job_number)
        G.node[job_number]['label'] = job
    
    for i,j,v in zip(cx.row, cx.col, cx.data):
        if v > THRESHOLD:
            G.add_edge(np.asscalar(i), np.asscalar(j))
            
    pos = nx.spring_layout(G)
        
    graph = json_graph.node_link_data(G)
    with open(PATH_PLOT + 'graph.json', 'w') as f:
        json.dump(graph, f, indent=4)

    


    </code>
  </pre>
</figure>
  
  <h3> Final Result </h3>
  
 <p> And here is the final result ! You can see that job are filtered so that we can represent it in a force directed graph.
  It was only for fun, but we should probably add something to display the strength of proximity between jobs. 
   Here we just show a link if the proximity is abova a fixed threshold</p>
<style>

.link {
  stroke: #777;
  stroke-opacity: 0.3;
  stroke-width: 1.5px;
}

.node circle {
  fill: #ccc;
  stroke: #000;
  stroke-width: 1.5px;
}

.node text {
  display: none;
  font: 10px sans-serif;
}

.node:hover circle {
  fill: #000;
}

.node:hover text {
  display: inline;
}

.cell {
  fill: none;
  pointer-events: all;
}

</style>
  
<script src="https://d3js.org/d3.v3.min.js"></script>
<script>

var width = 960,
    height = 500

var svg = d3.select("body").append("svg")
    .attr("width", width)
    .attr("height", height);

var force = d3.layout.force()
    .gravity(0.1)
    .charge(-120)
    .linkDistance(30)
    .size([width, height]);

var voronoi = d3.geom.voronoi()
    .x(function(d) { return d.x; })
    .y(function(d) { return d.y; })
    .clipExtent([[0, 0], [width, height]]);

d3.json("https://raw.githubusercontent.com/thibaultbl/thibaultbl.github.io/master/img/graph.json", function(error, json) {
  if (error) throw error;

  force
      .nodes(json.nodes)
      .links(json.links)
      .start();

  var link = svg.selectAll(".link")
      .data(json.links)
    .enter().append("line")
      .attr("class", "link");

  var node = svg.selectAll(".node")
      .data(json.nodes)
    .enter().append("g")
      .attr("class", "node")
      .call(force.drag);

  var circle = node.append("circle")
      .attr("r", 4.5);

  var label = node.append("text")
      .attr("dy", ".35em")
      .text(function(d) { return d.label; });

  var cell = node.append("path")
      .attr("class", "cell");

  force.on("tick", function() {
    cell
        .data(voronoi(json.nodes))
        .attr("d", function(d) { return d.length ? "M" + d.join("L") : null; });

    link
        .attr("x1", function(d) { return d.source.x; })
        .attr("y1", function(d) { return d.source.y; })
        .attr("x2", function(d) { return d.target.x; })
        .attr("y2", function(d) { return d.target.y; });

    circle
        .attr("cx", function(d) { return d.x; })
        .attr("cy", function(d) { return d.y; });

    label
        .attr("x", function(d) { return d.x + 8; })
        .attr("y", function(d) { return d.y; });
  });
});

</script>
   
    
</body>
</html>
